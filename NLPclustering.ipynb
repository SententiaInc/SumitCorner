{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "comments collected\n"
     ]
    }
   ],
   "source": [
    "import os,sys,csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "\n",
    "sf_all = 1\n",
    "num_clusters = 5\n",
    "#sf_all = int(sys.argv[1])\n",
    "#num_clusters = int(sys.argv[2])\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "model_path = 'train_data/GoogleNews-vectors-negative300.bin'\n",
    "w2v_model = word2vec.Word2Vec.load_word2vec_format(model_path, binary=True)\n",
    "index2word_set = set(w2v_model.index2word)\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "data_path = 'test_data/'\n",
    "sf_data = pd.read_csv(data_path+\"statefarm_facebook_statuses.csv\", header=0,sep=\",\" ).fillna('')\n",
    "fpg_data = pd.read_csv(data_path+\"flotheprogressivegirl_facebook_statuses.csv\", header=0,sep=\",\" ).fillna('')\n",
    "geico_data = pd.read_csv(data_path+\"geico_facebook_statuses.csv\", header=0,sep=\",\" ).fillna('')\n",
    "lm_data = pd.read_csv(data_path+\"libertymutual_facebook_statuses.csv\", header=0,sep=\",\" ).fillna('')\n",
    "nation_data = pd.read_csv(data_path+\"nationwide_facebook_statuses.csv\", header=0,sep=\",\" ).fillna('')\n",
    "pro_data = pd.read_csv(data_path+\"progressive_facebook_statuses.csv\", header=0,sep=\",\" ).fillna('')\n",
    "as_data = pd.read_csv(data_path+\"allstate_facebook_statuses.csv\", header=0,sep=\",\" ).fillna('')\n",
    "\n",
    "def clean_sentence(msg):\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \", msg)\n",
    "    words = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    word_vec = [w for w in words if not w in stops]\n",
    "    return(word_vec)\n",
    "\n",
    "def load_data(all_data = True):\n",
    "    if all_data:\n",
    "        facebook_status = pd.concat([sf_data,fpg_data,geico_data,lm_data,nation_data,pro_data,as_data],ignore_index=True)\n",
    "    else:\n",
    "        facebook_status = sf_data\n",
    "    return facebook_status\n",
    "    \n",
    "facebook_status = load_data(sf_all)\n",
    "num_col = facebook_status.shape[0]\n",
    "comments = np.zeros([num_col,300]) \n",
    "\n",
    "print('data loaded')\n",
    "\n",
    "numVec = np.zeros((300,),dtype=\"float32\")\n",
    "denom = 0\n",
    "for i in range(num_col):\n",
    "    word_vec = clean_sentence(facebook_status['status_message'][i])\n",
    "    for word in word_vec:\n",
    "        if word in index2word_set: \n",
    "            denom = denom + 1.\n",
    "            numVec = np.add(numVec,w2v_model[word])\n",
    "    comments[i,:] = np.divide(numVec,denom)\n",
    "\n",
    "print('comments collected')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "#num_clusters = 5\n",
    "kmeans = KMeans( n_clusters = num_clusters , random_state = 701 )\n",
    "idx = kmeans.fit_predict(comments)\n",
    "#np.savetxt('idx.data',idx)\n",
    "\n",
    "if sf_all:\n",
    "  data_file = 'all_idx.data'\n",
    "else:\n",
    "  data_file = 'sf_idx.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering completed\n"
     ]
    }
   ],
   "source": [
    "fw = open(data_file, 'w')\n",
    "for i in range(num_col):\n",
    "    if i < sf_data.shape[0]:\n",
    "        fw.write('%s StateFarm %d\\n'%(facebook_status['status_id'][i],idx[i]))\n",
    "    elif i < sf_data.shape[0] + fpg_data.shape[0]:\n",
    "        fw.write('%s FlotheProgressiveGirl %d\\n'%(facebook_status['status_id'][i],idx[i]))\n",
    "    elif i < sf_data.shape[0] + fpg_data.shape[0] + geico_data.shape[0]:\n",
    "        fw.write('%s Geico %d\\n'%(facebook_status['status_id'][i],idx[i]))\n",
    "    elif i < sf_data.shape[0] + fpg_data.shape[0] + geico_data.shape[0] + lm_data.shape[0]:\n",
    "        fw.write('%s LibertyMutual %d\\n'%(facebook_status['status_id'][i],idx[i]))\n",
    "    elif i < sf_data.shape[0] + fpg_data.shape[0] + geico_data.shape[0] + lm_data.shape[0] + nation_data.shape[0]:\n",
    "        fw.write('%s Nationwide %d\\n'%(facebook_status['status_id'][i],idx[i]))\n",
    "    elif i < sf_data.shape[0] + fpg_data.shape[0] + geico_data.shape[0] + lm_data.shape[0] + nation_data.shape[0] + pro_data.shape[0]:\n",
    "        fw.write('%s Progressive %d\\n'%(facebook_status['status_id'][i],idx[i]))\n",
    "    else:\n",
    "    \tfw.write('%s AllState %d\\n'%(facebook_status['status_id'][i],idx[i]))\n",
    "fw.close()\n",
    "\n",
    "print('clustering completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50138985328_10150732198950329 StateFarm 3\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
